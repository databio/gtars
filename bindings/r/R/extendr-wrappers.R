# Generated by extendr: Do not edit by hand

# nolint start

#
# This file was created with the following call:
#   .Call("wrap__make_gtars_wrappers", use_symbols = TRUE, package_name = "gtars")

#' @usage NULL
#' @useDynLib gtars, .registration = TRUE
NULL

`__init__` <- function() invisible(.Call(wrap____init__))

#' Write tokens to a gtok file
#' @export
#' @param filename A string representing the path to the gtok file.
read_tokens_from_gtok <- function(filename) .Call(wrap__r_read_tokens_from_gtok, filename)

#' Write tokens to a gtok file
#' @export
#' @param filename A string representing the path to the gtok file.
#' @param tokens The tokens to write.
write_tokens_to_gtok <- function(filename, tokens) invisible(.Call(wrap__r_write_tokens_to_gtok, filename, tokens))

#' Create an IGD database from a directory of bed files
#' @param output_path String path where the IGD database will be saved
#' @param filelist String path to either a text file containing paths to bed files, or a directory containing bed files
#' @param db_name String name for the database (will be used in output filenames)
rextendr_igd_create <- function(output_path, filelist, db_name) .Call(wrap__rextendr_igd_create, output_path, filelist, db_name)

#' Search igd with a bed file
#' @param database_path A string representing the path to the database igd file.
#' @param query_path A string representing the path to the query bed file.
rextendr_igd_search <- function(database_path, query_path) .Call(wrap__rextendr_igd_search, database_path, query_path)

Tokenizer <- new.env(parent = emptyenv())

Tokenizer$new <- function(chrs, starts, ends) .Call(wrap__Tokenizer__new, chrs, starts, ends)

Tokenizer$tokenize <- function(gr) invisible(.Call(wrap__Tokenizer__tokenize, self, gr))

Tokenizer$universe_length <- function() .Call(wrap__Tokenizer__universe_length, self)

#' @export
`$.Tokenizer` <- function (self, name) { func <- Tokenizer[[name]]; environment(func) <- environment(); func }

#' @export
`[[.Tokenizer` <- `$.Tokenizer`


# nolint end
